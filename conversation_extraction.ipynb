{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6351c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from extract_conversations import BurrConversationExtractor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671e5756",
   "metadata": {},
   "source": [
    "## 1. Initialize the Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07164591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the extractor\n",
    "extractor = BurrConversationExtractor(burr_storage_dir=\"~/.burr\")\n",
    "\n",
    "# List available projects\n",
    "projects = extractor.list_projects()\n",
    "print(f\"Found {len(projects)} projects:\")\n",
    "for proj in projects:\n",
    "    apps = extractor.list_applications(proj)\n",
    "    print(f\"  - {proj}: {len(apps)} applications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f10a49",
   "metadata": {},
   "source": [
    "## 2. Extract All Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebbe25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all conversations from all projects\n",
    "conversations = extractor.extract_all_conversations()\n",
    "\n",
    "print(f\"\\nExtracted {len(conversations)} total conversations\")\n",
    "print(f\"Total turns across all conversations: {sum(c['total_turns'] for c in conversations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e690c5a9",
   "metadata": {},
   "source": [
    "## 3. Explore a Single Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01764700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the first conversation in detail\n",
    "if conversations:\n",
    "    conv = conversations[0]\n",
    "    print(f\"Project: {conv['project_id']}\")\n",
    "    print(f\"App ID: {conv['app_id']}\")\n",
    "    print(f\"Total Turns: {conv['total_turns']}\")\n",
    "    print(f\"Total Actions: {conv['metadata']['total_actions']}\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    # Display each turn\n",
    "    for turn in conv['turns']:\n",
    "        print(f\"\\nTurn {turn['turn_number']}:\")\n",
    "        print(\"-\" * 40)\n",
    "        for msg in turn['messages']:\n",
    "            role = msg['role'].upper()\n",
    "            content = msg['content'][:200] + \"...\" if len(msg['content']) > 200 else msg['content']\n",
    "            print(f\"\\n[{role}]: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb2b166",
   "metadata": {},
   "source": [
    "## 4. Convert to DataFrame for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9201d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a flattened DataFrame for easier analysis\n",
    "rows = []\n",
    "\n",
    "for conv in conversations:\n",
    "    for turn in conv['turns']:\n",
    "        turn_data = {\n",
    "            'conversation_id': conv['app_id'],\n",
    "            'project_id': conv['project_id'],\n",
    "            'turn_number': turn['turn_number'],\n",
    "            'num_messages_in_turn': len(turn['messages'])\n",
    "        }\n",
    "        \n",
    "        # Extract user and assistant messages\n",
    "        for msg in turn['messages']:\n",
    "            if msg['role'] == 'user':\n",
    "                turn_data['user_message'] = msg['content']\n",
    "                turn_data['user_message_length'] = len(msg['content'])\n",
    "            elif msg['role'] == 'assistant':\n",
    "                turn_data['assistant_message'] = msg['content']\n",
    "                turn_data['assistant_message_length'] = len(msg['content'])\n",
    "        \n",
    "        rows.append(turn_data)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(f\"Created DataFrame with {len(df)} turns\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15613c82",
   "metadata": {},
   "source": [
    "## 5. Conversation Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea0e100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"CONVERSATION STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nTotal Conversations: {df['conversation_id'].nunique()}\")\n",
    "print(f\"Total Turns: {len(df)}\")\n",
    "print(f\"\\nAverage turns per conversation: {len(df) / df['conversation_id'].nunique():.2f}\")\n",
    "print(f\"\\nMessage Length Statistics:\")\n",
    "print(f\"  User messages:\")\n",
    "print(f\"    - Mean: {df['user_message_length'].mean():.0f} chars\")\n",
    "print(f\"    - Median: {df['user_message_length'].median():.0f} chars\")\n",
    "print(f\"  Assistant messages:\")\n",
    "print(f\"    - Mean: {df['assistant_message_length'].mean():.0f} chars\")\n",
    "print(f\"    - Median: {df['assistant_message_length'].median():.0f} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ec453d",
   "metadata": {},
   "source": [
    "## 6. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9391dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Turns per conversation\n",
    "turns_per_conv = df.groupby('conversation_id')['turn_number'].max()\n",
    "axes[0, 0].hist(turns_per_conv, bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Number of Turns')\n",
    "axes[0, 0].set_ylabel('Number of Conversations')\n",
    "axes[0, 0].set_title('Distribution of Turns per Conversation')\n",
    "\n",
    "# 2. Message length distribution\n",
    "axes[0, 1].hist(df['user_message_length'], bins=30, alpha=0.5, label='User', edgecolor='black')\n",
    "axes[0, 1].hist(df['assistant_message_length'], bins=30, alpha=0.5, label='Assistant', edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Message Length (characters)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Message Length Distribution')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 3. Turn progression\n",
    "turn_stats = df.groupby('turn_number').agg({\n",
    "    'user_message_length': 'mean',\n",
    "    'assistant_message_length': 'mean'\n",
    "})\n",
    "turn_stats.plot(ax=axes[1, 0], marker='o')\n",
    "axes[1, 0].set_xlabel('Turn Number')\n",
    "axes[1, 0].set_ylabel('Average Message Length')\n",
    "axes[1, 0].set_title('Message Length by Turn Number')\n",
    "axes[1, 0].legend(['User', 'Assistant'])\n",
    "\n",
    "# 4. Conversations by project\n",
    "project_counts = df.groupby('project_id')['conversation_id'].nunique()\n",
    "axes[1, 1].bar(range(len(project_counts)), project_counts.values, alpha=0.7, edgecolor='black')\n",
    "axes[1, 1].set_xlabel('Project')\n",
    "axes[1, 1].set_ylabel('Number of Conversations')\n",
    "axes[1, 1].set_title('Conversations per Project')\n",
    "axes[1, 1].set_xticks(range(len(project_counts)))\n",
    "axes[1, 1].set_xticklabels([p[:20] + '...' if len(p) > 20 else p for p in project_counts.index], rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a69ca5",
   "metadata": {},
   "source": [
    "## 7. Extract Actions Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d5e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze action sequences\n",
    "if conversations:\n",
    "    conv = conversations[0]\n",
    "    \n",
    "    print(\"Action Timeline for First Conversation:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    actions_df = pd.DataFrame(conv['actions'])\n",
    "    \n",
    "    if not actions_df.empty:\n",
    "        # Calculate duration for each action\n",
    "        if 'start_time' in actions_df.columns and 'end_time' in actions_df.columns:\n",
    "            actions_df['start_dt'] = pd.to_datetime(actions_df['start_time'])\n",
    "            actions_df['end_dt'] = pd.to_datetime(actions_df['end_time'])\n",
    "            actions_df['duration_ms'] = (actions_df['end_dt'] - actions_df['start_dt']).dt.total_seconds() * 1000\n",
    "        \n",
    "        display(actions_df[['sequence_id', 'action', 'duration_ms']].head(20))\n",
    "        \n",
    "        # Action summary\n",
    "        print(\"\\nAction Summary:\")\n",
    "        action_summary = actions_df.groupby('action').agg({\n",
    "            'sequence_id': 'count',\n",
    "            'duration_ms': 'mean'\n",
    "        }).rename(columns={'sequence_id': 'count', 'duration_ms': 'avg_duration_ms'})\n",
    "        display(action_summary.sort_values('count', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1818a3",
   "metadata": {},
   "source": [
    "## 8. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da10cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the extracted conversations to JSON\n",
    "output_file = \"extracted_conversations.json\"\n",
    "extractor.save_to_json(conversations, output_file)\n",
    "\n",
    "# Also save the DataFrame as CSV for easier analysis\n",
    "df.to_csv(\"conversation_turns.csv\", index=False)\n",
    "print(\"✓ Saved conversation turns to conversation_turns.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d8fc63",
   "metadata": {},
   "source": [
    "## 9. Export for Multi-Turn Evaluation\n",
    "\n",
    "Format the data specifically for evaluation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b446a162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluation format\n",
    "eval_data = []\n",
    "\n",
    "for conv in conversations:\n",
    "    eval_conv = {\n",
    "        \"conversation_id\": conv[\"app_id\"],\n",
    "        \"project_id\": conv[\"project_id\"],\n",
    "        \"metadata\": conv[\"metadata\"],\n",
    "        \"turns\": []\n",
    "    }\n",
    "    \n",
    "    for turn in conv[\"turns\"]:\n",
    "        eval_turn = {\n",
    "            \"turn_number\": turn[\"turn_number\"],\n",
    "            \"user_input\": None,\n",
    "            \"assistant_response\": None,\n",
    "            \"context\": []\n",
    "        }\n",
    "        \n",
    "        for msg in turn[\"messages\"]:\n",
    "            if msg[\"role\"] == \"user\":\n",
    "                eval_turn[\"user_input\"] = {\n",
    "                    \"text\": msg[\"content\"],\n",
    "                    \"type\": msg[\"type\"]\n",
    "                }\n",
    "            elif msg[\"role\"] == \"assistant\":\n",
    "                eval_turn[\"assistant_response\"] = {\n",
    "                    \"text\": msg[\"content\"],\n",
    "                    \"type\": msg[\"type\"]\n",
    "                }\n",
    "        \n",
    "        eval_conv[\"turns\"].append(eval_turn)\n",
    "    \n",
    "    eval_data.append(eval_conv)\n",
    "\n",
    "# Save evaluation format\n",
    "with open(\"conversations_for_evaluation.json\", \"w\") as f:\n",
    "    json.dump(eval_data, f, indent=2)\n",
    "\n",
    "print(f\"✓ Exported {len(eval_data)} conversations in evaluation format\")\n",
    "print(\"  File: conversations_for_evaluation.json\")\n",
    "\n",
    "# Show example\n",
    "if eval_data:\n",
    "    print(\"\\nExample conversation structure:\")\n",
    "    print(json.dumps(eval_data[0], indent=2)[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a88e376",
   "metadata": {},
   "source": [
    "## 10. Multi-Turn Metrics\n",
    "\n",
    "Calculate metrics useful for multi-turn evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf49ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate multi-turn specific metrics\n",
    "metrics = []\n",
    "\n",
    "for conv in conversations:\n",
    "    conv_metrics = {\n",
    "        \"conversation_id\": conv[\"app_id\"],\n",
    "        \"total_turns\": conv[\"total_turns\"],\n",
    "        \"total_messages\": conv[\"metadata\"][\"total_messages\"],\n",
    "        \"total_actions\": conv[\"metadata\"][\"total_actions\"],\n",
    "        \"actions_per_turn\": conv[\"metadata\"][\"total_actions\"] / max(conv[\"total_turns\"], 1),\n",
    "        \"avg_user_message_length\": 0,\n",
    "        \"avg_assistant_message_length\": 0,\n",
    "        \"turn_types\": []\n",
    "    }\n",
    "    \n",
    "    user_lengths = []\n",
    "    assistant_lengths = []\n",
    "    \n",
    "    for turn in conv[\"turns\"]:\n",
    "        turn_type = \"multi_message\" if len(turn[\"messages\"]) > 2 else \"standard\"\n",
    "        conv_metrics[\"turn_types\"].append(turn_type)\n",
    "        \n",
    "        for msg in turn[\"messages\"]:\n",
    "            if msg[\"role\"] == \"user\":\n",
    "                user_lengths.append(len(msg[\"content\"]))\n",
    "            elif msg[\"role\"] == \"assistant\":\n",
    "                assistant_lengths.append(len(msg[\"content\"]))\n",
    "    \n",
    "    if user_lengths:\n",
    "        conv_metrics[\"avg_user_message_length\"] = sum(user_lengths) / len(user_lengths)\n",
    "    if assistant_lengths:\n",
    "        conv_metrics[\"avg_assistant_message_length\"] = sum(assistant_lengths) / len(assistant_lengths)\n",
    "    \n",
    "    metrics.append(conv_metrics)\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "print(\"Multi-Turn Evaluation Metrics:\")\n",
    "display(metrics_df)\n",
    "\n",
    "# Save metrics\n",
    "metrics_df.to_csv(\"conversation_metrics.csv\", index=False)\n",
    "print(\"\\n✓ Saved metrics to conversation_metrics.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
